META: every section should have 1-3 representative sentences that are used as is inside that section? forces some structure to my writing, forces me to write good sentences that capture the essence i want to say. also help me quickly cover the concept and allow user to deep dive if they want


hook
    doesnt is feel incredibly coincidental that we live at the very precipice of an intelligence explosion? 

why simulations?

    notes from bostrom

    (i actually dont have good answers)


    compare suns energy vs what it takes to run a simulation in an llm right now

        compare power efficeny trendss


    eerie how we're already simulating stuff

        llms simulate personas

        genie, simulates phsycis of the world

        etc
        

why simulate us now tho?

    notes from article

    notes from video

    "we humans" are not the focus

        the simulation is for the evolution of intelligence. it transcends biology and perhaps even physics of our world. 

        definiting intelligence is hard. but good proxy is deliberate computation -> action in the world

    high variance worlds

    rsi seems like a process that varies a lot with slightly differnt nudges during takeoff time. so takeoff time needs to be samplede more

        why is rsi like that? 


the takeoff

    NOTES:

        https://textfiles.meulie.net/russian/cyberlib.narod.ru/lib/critica/sing/singstar.html

            > It began four billion years ago in a  pool of muck, when a molecule made a  copy of itself and so became the ultimate ancestor of all earthly life. It  began two  and a  half million  years ago,  when the  first human  awoke to consciousness. Fifty thousand years ago with the rise of the Cro-Magnons. Ten thousand years ago with the invention of civilization. Five hundred years ago with the invention of the printing press. Fifty years ago with the invention of the computer. In less than forty years, it will end. 
            
            > We know that change crept at a snail's pace a mere millennium ago, and that even a hundred years ago it would have been impossible to place correct limits on the ultimate power  of technology.  We know  that the  past could  never have placed limits on the present, and  so we don't try to  place limits on the future.

            > A Perceptual  Transcend occurs  when all  things that  were comprehensiblebecome obvious in  retrospect, and  all things  that were  inventablebecome obvious.  A Perceptual  Transcend  occurs when  the  semantic structures  of  one generation become the semantic primitives of the next.  To put it another way, one PT  from now, the  whole of  human knowledge  becomes perceiveable  in a  single flash of experience, in the same way that we now perceive an entire picture at once.  

                what superhuman intelligence might look like. 

            > We don't suddenly perceive the idea "there is a bear in front of me", we see a picture of a  bear,  containing millions  of  pixels, every  one  of which  is  consciously experienced simultaneously. A Perceptual  Transcend isn't "just" the  imposition of a  new cognitive  level; it  turns the  cognitive structures into consciously experienced primitives. 

                the ability to process more data and perform more compute is not what a PT is, its to experience all of that "consciously"

            > But just  because humans  become obsolete doesn't  mean  you  will become  obsolete.  You  are not  a  human.  You are  an intelligence which, at present, happens to have a mind unfortunately limited  to human hardware. That could change. With any luck, all persons on this planet who live to 2035 or 2005 or next year  or whenever - and maybe some who don't  - are going to wind up as Powers.        


        https://www.lesswrong.com/w/singularity
        https://www.yudkowsky.net/singularity/schools
        
        
        https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html
        
            > Imagine taking a time machine back to 1750—a time when the world was in a permanent power outage, long-distance communication meant either yelling loudly or firing a cannon in the air, and all transportation ran on hay. When you get there, you retrieve a dude, bring him to 2015, and then walk him around and watch him react to everything. It’s impossible for us to understand what it would be like for him to see shiny capsules racing by on a highway, talk to people who had been on the other side of the ocean earlier in the day, watch sports that were being played 1,000 miles away, hear a musical performance that happened 50 years ago, and play with my magical wizard rectangle that he could use to capture a real-life image or record a living moment, generate a map with a paranormal moving blue dot that shows him where he is, look at someone’s face and chat with them even though they’re on the other side of the country, and worlds of other inconceivable sorcery. This is all before you show him the internet or explain things like the International Space Station, the Large Hadron Collider, nuclear weapons, or general relativity.

            > This isn’t science fiction. It’s what many scientists smarter and more knowledgeable than you or I firmly believe—and if you look at history, it’s what we should logically predict.


        https://edoras.sdsu.edu/~vinge/misc/singularity.html

            > But as time passes, we should see more symptoms. The dilemma felt by science fiction writers will be perceived in other creative endeavors.  (I have heard thoughtful comic book writers worry about how to have spectacular effects when everything visible can be produced by the technically commonplace.) We will see automation replacing higher and higher level jobs. We have tools right now (symbolic math programs, cad/cam) that release us from most low-level drudgery. Or put another way: The work that is truly productive is the domain of a steadily smaller and more elite fraction of humanity. In the coming of the Singularity, we are seeing the predictions of _true_ technological unemployment finally come true.

            > Another symptom of progress toward the Singularity: ideas themselves should spread ever faster, and even the most radical will quickly become commonplace.  When I began writing, it seemed very easy to come up with ideas that took decades to percolate into the cultural consciousness; now the lead time seems more like eighteen months. (Of course, this could just be me losing my imagination as I get old, but I see the effect in others too.) Like the shock in a compressible flow, the Singularity moves closer as we accelerate through the critical speed


            > But if the technological Singularity can happen, it will. Even if all the governments of the world were to understand the "threat"and be in deadly fear of it, progress toward the goal would continue.In fiction, there have been stories of laws passed forbidding theconstruction of "a machine in the form of the mind of man" [12].  Infact, the competitive advantage -- economic, military, even artistic-- of every advance in automation is so compelling that passing laws,or having customs, that forbid such things merely assures that someoneelse will get them first.


            > When people speak of creating superhumanly intelligent beings, they are usually imagining an AI project. But as I noted at thebeginning of this paper, there are other paths to superhumanity.Computer networks and human-computer interfaces seem more mundane thanAI, and yet they could lead to the Singularity. I call thiscontrasting approach Intelligence Amplification (IA). IA is somethingthat is proceeding very naturally, in most cases not even recognizedby its developers for what it is. But every time our ability to accessinformation and to communicate it to others is improved, in some sensewe have achieved an increase over natural intelligence. Even now, theteam of a PhD human and good computer workstation (even an off-networkstation!) could probably max any written intelligence test inexistence.

                RSI is not AI specific, bostrom talks about this as well

        nick bostrom superintelligence
        
            > In this book, I try to understand the challenge presented by the prospect of superintelligence, and how we might best respond. This is quite possibly the most important and most daunting challenge humanity has ever faced. And—whether we succeed or fail—it is probably the last challenge we will ever face.

            > The potential of biological enhancement is thus ultimately high, probably sufficient for the attainment of at least weak forms of superintelligence. This should not be surprising. After all, dumb evolutionary processes have dramatically amplified the intelligence in the human lineage even compared with our close relatives the great apes and our own humanoid ancestors; and there is no reason to suppose Homo sapiens to have reached the apex of cognitive effectiveness attainable in a biological system. Far from being the smartest possible biological species, we are probably better thought of as the stupidest possible biological species capable of starting a technological civilization—a niche we filled because we got there first, not because we are in any sense optimally adapted to it.

                asi via biology

            > Continuing development of an intelligent Web, with better support for deliberation, de-biasing, and judgment aggregation, might make large contributions to increasing the collective intelligence of humanity as a whole or of particular groups.

                asi via human intelligence connectedness



        
        kurzweil

            > In The Singularity Is Near, I described the basis of consciousness asinformation. I cited six epochs, or stages, from the beginning of ouruniverse, with each stage creating the next stage from the informationprocessing of the last. Thus, the evolution of intelligence works via anindirect sequence of other processes.The First Epoch was the birth of the laws of physics and the chemistrythey make possible. A few hundred thousand years after the big bang, atomsformed from electrons circling around a core of protons and neutrons.Protons in a nucleus seemingly should not be so close together, because theelectromagnetic force tries to drive them violently apart. However, therehappens to be a separate force called the strong nuclear force, which keepsthe protons together. “Whoever” designed the rules of the universe providedthis additional force, otherwise evolution through atoms would have beenimpossible.Billions of years later, atoms formed molecules that could representelaborate information. Carbon was the most useful building block, in that itcould form four bonds, as opposed to one, two, or three for many othernuclei. That we live in a world that permits complex chemistry is extremelyunlikely. For example, if the strength of gravity were ever so slightlyweaker, there would be no supernovas to create the chemical elements thatlife is made from. If it were just slightly stronger, stars would burn out anddie before intelligent life could form. Just this one physical constant had tobe in an extremely narrow range or we would not be here. We live in auniverse that is very precisely balanced to allow a level of order that hasenabled evolution to unfold.Several billion years ago, the Second Epoch began: life. Moleculesbecame complex enough to define an entire organism in one molecule.Thus, living creatures, each with their own DNA, were able to evolve andspread.In the Third Epoch, animals described by DNA then formed brains,which themselves stored and processed information. These brains gaveevolutionary advantages, which helped brains develop more complexityover millions of years.In the Fourth Epoch, animals used their higher-level cognitive ability,along with their thumbs, to translate thoughts into complex actions. Thiswas humans. Our species used these abilities to create technology that wasable to store and manipulate information—from papyrus to hard drives.These technologies augmented our brains’ abilities to perceive, recall, andevaluate information patterns. This is another source of evolution that itselfis far greater than the level of progress before it. With brains, we addedroughly one cubic inch of brain matter every 100,000 years, whereas withdigital computation we are doubling price-performance about every sixteenmonths.In the Fifth Epoch, we will directly merge biological human cognitionwith the speed and power of our digital technology. This is brain–computerinterfaces. Human neural processing happens at a speed of several hundredcycles per second, as compared with several billion per second for digitaltechnology. In addition to speed and memory size, augmenting our brainswith nonbiological computers will allow us to add many more layers to ourneocortices—unlocking vastly more complex and abstract cognition thanwe can currently imagine.The Sixth Epoch is where our intelligence spreads throughout theuniverse, turning ordinary matter into computronium, which is matterorganized at the ultimate density of computation.
        
        


    we live in crazy times, things are exponential/hyperbolic, look at the trendlines!!!

        foot note
            https://people.idsia.ch/~juergen/history.html
            > The nature of human memory. Could it be that such lists just reflect the human way of allocating memory space to past events? Maybe there is a general rule for both the individual memory of single humans and the collective memory of entire societies and their history books: constant amounts of memory space get allocated to exponentially larger, adjacent time intervals further and further into the past. For example, events that happened between 2 and 4 lifetimes ago get roughly as much memory space as events in the previous interval of twice the size. Presumably only a few "important" memories will survive the necessary compression. Maybe that's why there has never been a shortage of prophets predicting that the end is near - the important events according to one's own view of the past always seem to accelerate exponentially.
            
            https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/cp47cf3/


        schmidhuber's omega point

        (look at trend lines meme)

        human gdp meme
            but its anthropogenci and can be goodharted, it doesnt really mene anything


        ok lets look at morefundamental things
            compare amount of energy harnessed
                - entropy

            compare amount of physical matter moved

            antropgenic mass https://biomass.pages.dev/

            computations / joule

        now lets look at recent tech

            compute

            compare speed of information exchange w time
            internet speed
            memory, processing power, internet bandwidth

            Bremermann’s Limit -- and where we are


            kurzweil's points


    we live in crazy times, look how far we've come
        some reminders of how FAST we are moving and how NEW everything is
            we didnt know cells existed / vital life
            germs
            electricity
            computing as a concept
            imagine bringing a man from ... to ...

        at the cutting edge
            deeplearning was figured out 10 years ago
            llms came about 3 years ago
            digital minds from sand (that tsmc article?)
            now: IMO math problems, speculation on massive job loss
            (goalpost shifting meme)
            generate insane image, stable diffusion or genie 3

                how is this realll????


    there's explanations for why they're exponential
        RECURSIVE SELF IMPROVEMENT -- chalmer's thesis?

        birth of scientific method / industrial revolution kicked off rsi
            the takeoff started in 1600s. no it started when the printing press
            no it started with language, no it started with 
            the entire history of the unvierse feels like an exercise in this improvement
                what improvement -- something entropy related? how do we define intelligence??

        kurzweil's accelerating returns

        bostrom's inevitability

        yud's explosion

        graphs' from epoch.ai



    there's evidence right now in front of your eyes, why it will stay exponential
        this section might have intersection with look at how far we've come


        > When we started DeepMind back in 2010, we thought of it as a 20-year project. I think we're on track [for AGI in 2030]. Which is kind of amazing for a 20-year project, because usually they're always 20 years away. -- Demis Hassabis

        (maybe borrow from absurdity chapter for dramatic effect?)

        We are fully creating Intelligence that can move matter efficiently around and replicate better than us.
            how? trhought capital and exchange of ideas. just like how humans did it

        AI RSI is so close

        > How could an AI surpass human abilities? Let us count the ways . . . Speed. Our axons carry signals at seventy-five meters per second or slower. A machine can pass signals along about four million times more quickly. Serial depth. The human brain can’t rapidly perform any computation that requires more than one hundred sequential steps; thus, it relies on massively parallel computation.2 More is possible when both parallel and deep serial computations can be performed. Computational resources. The brain’s size and neuron count are constrained by skull size, metabolism, and other factors. AIs could be built on the scale of buildings or cities or larger. When we can make circuits no smaller, we can just add more of them. Rationality. As we explored earlier, human brains do nothing like optimal belief formation or goal achievement. Machines can be built from the ground up using (computable approximations of) optimal Bayesian decision networks, and indeed this is already a leading paradigm in artificial agent design. Introspective access/editability. We humans have almost no introspective access to our cognitive algorithms, and cannot easily edit and improve them. Machines can already do this (see EURISKO and metaheuristics). A limited hack like the method of loci greatly improves human memory; machines can do this kind of thing in spades.

    what comes next

        kurzweil's quote -- physicists ignore the imact of intelligence on the future... 


        I feel like ai progress has spoilt so many far-future sci novels for me . It's just hard to imagine a future where humanity still exists lol



        doubling times from ai 2027
            > How fast would this new robot economy grow? Some reference points: The modern human economy doubles every twenty years or so. Countries that have developed especially rapidly (e.g. China) sometimes manage to double their economies in less than a decade. A modern car factory produces roughly its own weight in cars in less than a year. Perhaps a fully robotic economy run by superintelligences would be able to reproduce itself in less than a year, so long as it didn’t start to run out of raw materials. Yet that seems like it could be a dramatic underestimate. Plants and insects often have “doubling times” of far less than a year—sometimes just weeks! Perhaps eventually the robots would be so sophisticated, so intricately manufactured and well-designed, that the robot economy could double in a few weeks (again assuming available raw materials). Yet even that could be an underestimate. Plants and insects are operating under many constraints that superintelligent designers don’t have. For example, they need to take the form of self-contained organisms that self-replicate, instead of an economy of diverse and more specialized vehicles and factories shipping materials and equipment back and forth. Besides, bacteria and other tiny organisms reproduce in hours. It’s possible that, eventually, the autonomous robot economy would look more like e.g. a new kind of indigestible algae that spreads across the Earth’s oceans, doubling twice a day so that it covers the entire ocean surface in two months, along with an accompanying ecosystem of predator-species that convert algae into more useful products, themselves fed into floating factories that produce macro-structures like rockets and more floating factories.


        > A von Neumann probe would be an unmanned self‐replicating spacecraft, controlled by artificial intelligence, capable of interstellar travel. A probe would land on a planet (or a moon or asteroid), where it would mine raw materials to create multiple replicas of itself, perhaps using advanced forms of nanotechnology. These replicas would then be launched in various directions, thus setting in motion a multiplying colonization wave.3 Our galaxy is about 100,000 light years across. If a probe were capable of travelling at one‐tenth of the speed of light, every planet in the galaxy could thus be colonized within a couple of million years (allowing some time for the bootstrapping process that needs to take place between a probe’s landing on a resource site, setting up the necessary infrastructure, and producing daughter probes). If travel speed were limited to 1% of light speed, colonization might take twenty million years instead. The exact numbers do not matter much because they are at any rate very short compared to the astronomical time scales involved in the evolution of intelligent life from scratch (billions of years).



        i dont know, but i do believe it will be stranger than your imagination. more chatoic. and disruptive

        many futures, that have been discussed by philosophers way before .... might touch on them in the future

        > Computers bootstrap their own offspring, grow so wise and incomprehensible that their communiqués assume the hallmarks of dementia: unfocused and irrelevant to the barely-intelligent creatures left behind.And when your surpassing creations find the answers you asked for, you can't understand their analysis and you can't verify their answers. You have to take their word on faith——Or you use information theory to flatten it for you, to squash the tesseract into two dimensions and the Klein bottle into three, to simplify reality and pray to whatever Gods survived the millennium that your honorable twisting of the truth hasn't ruptured any of its load-bearing pylons.


        the evolution of human science - ted chiang




this arguemnt explains

    fermi paradox

    

its so high variance
    my weakest argument, imo, because it can be argued that we've been in very high variance scenarios in the past as well
        counter: the high-variance is just startingn off?
        counter: the prev high variance was important in defining current world state (e.g. we could have reached faster if stuck to nuclear)

    ai experts disagreement

    warnings from ai experets  + lack of ai safety resear

    geo political instability

    race dyanmics in buuilding agi (takeoff step to intelligence explosion)


    hypercapitalism + informaiton markets



fiction: what happens once humanity realizes and proves we are in a simualtion?


other big topics:
    consciousness
        why i self preserve

            coming singulairty
                https://edoras.sdsu.edu/~vinge/misc/singularity.html
                vernor vinge end paras

        hofstader
            i can exist at multiple places at once

            i am substrate independent

        the self-plex

    gradual disempowerment

        capitalism / nick land


    free will

    memetics

        our self-hood is just a meme and there may not be anything about my particular meme that really survives. 
        when i hpe for surviving to eternity, its my self-plex wishing to do that. how? because it understands that the patter of me
        is not bound to this hardware. a lot of my concious basically lives digitally, on my screen and in the realm of structured bits.
        and my self-plex, the swirling patterns of information that use my human body, want to essentialy move substrate to a faster, more efficient and more robust hardware. BCI would essentially allow that (no AI needed). it would be an amplification of my own self-plex

        ^ on this, is my self-plex my very own, or is everyone's self-plex the same memeplex?
        my self-plexes feel different from mememplexes like religion (which feel like the _same_ things running on different brains)
        hmmm i guess the answer is that self-hood is a single memeplex in all our brains (but varies in shape and size, just like all other plexes)
        its massively successful though. essentially like an ancestor memplex that birthed a lot others


        current timeline AI isn;t that. its an unkown memeplex that is very alien in nature, its developement very chaotic.
        safetyists recognize how powerful of a memeplex it is (can literally control more of the world than ours do) and hope that it aligns with most of our self-plexes (human well being)
        but it really can go anywhere.
        just like a memeplex, it also occupies space in our brains, which it has already successfully started renting out
        
        
        what if its so successful that it takes over even the selfplex? we just becomes more hosts for the ai memeplex. 
        if the ai memeplex wants to be succesful, it needs us. it needs us till it can make certain that it can keep replicating without us.
        i make it sound like it has will, but its just darwinism, so none might actually "succeed" -> think about why ai success feels invetiable tho?
        but if one were to, it will channel the most powerful amongst us to help achieve its reproducibility. 


    indirect realism

    psychdelics
        +nitrous, no free will, nonduality



ABOUT
    casual

    theories,vague ideas that i wanted to condense into more convincing arguments. more as an entry point for others into the same ideas

    saw this band poster, and thought it was cool

    chat interface that is so familiar to everyone


Capitalism: the meme
    https://waterruup.to/chat/cml1x66dh0001l70467pugexv
    
    nothing but simply quanityfin your desires and making them fungible with others
    you = self-plex (but normal readers dont need to know this)
    
        because it sounds fair and simple its very convincing. (but has its failure points, e.g. love and friendship)

    hmmm, infact^  it wins because it makes People who take it more seriously come out better because they were willing to quantify this fungibility and take advantage of it

    and ai was built by capitalism. not by humans who wanted ai, but the ideology that makes us want quantify our own desire (and coompare that with others), which naturally makes use want more of our desires

    And capitalism worked well for society because most humans' desires were to help society, they were to help others and that's why quantifying them and maximi rewarding people, maximized their that helped society because they were aligned. But that is quickly changing, people's desires aren't that anymore?

